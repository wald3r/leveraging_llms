{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC1Vc3OBzxxw"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets evaluate transformers langchain langchain-openai faiss-cpu langchain-community llamaapi\n",
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5Tokenizer,\n",
        "    BartForConditionalGeneration, BartTokenizer,\n",
        ")\n",
        "from transformers import (\n",
        "    MT5ForConditionalGeneration, MT5Tokenizer,\n",
        "    LEDForConditionalGeneration, LEDTokenizer,\n",
        "    PegasusForConditionalGeneration, PegasusTokenizer\n",
        ")\n",
        "\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset, Dataset\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LFgYsnPl1UEe"
      },
      "outputs": [],
      "source": [
        "#HF_TOKEN =#token\n",
        "MASKED_MODEL_CONFIG = [\n",
        "    {\n",
        "        \"name\": \"LED-Base\",\n",
        "        \"model_cls\": LEDForConditionalGeneration,\n",
        "        \"tokenizer_cls\": LEDTokenizer,\n",
        "        \"pretrained\": \"allenai/led-base-16384\",\n",
        "        \"out_dir\": \"/content/drive/MyDrive/models/role-aware-rag/led-base\"\n",
        "    },\n",
        "  {\n",
        "      \"name\": \"BART-Base\",\n",
        "       \"model_cls\": BartForConditionalGeneration,\n",
        "        \"tokenizer_cls\": BartTokenizer,\n",
        "        \"pretrained\": \"facebook/bart-base\",\n",
        "       \"out_dir\": \"/content/drive/MyDrive/models/role-aware-rag/bart-base\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"T5-Base\",\n",
        "        \"model_cls\": T5ForConditionalGeneration,\n",
        "        \"tokenizer_cls\": T5Tokenizer,\n",
        "        \"pretrained\": \"t5-base\",\n",
        "        \"out_dir\": \"/content/drive/MyDrive/models/role-aware-rag/t5-base\"\n",
        "    },\n",
        "\n",
        "  {\n",
        "        \"name\": \"DistilBART\",\n",
        "       \"model_cls\": BartForConditionalGeneration,\n",
        "       \"tokenizer_cls\": BartTokenizer,\n",
        "        \"pretrained\": \"sshleifer/distilbart-cnn-12-6\",\n",
        "        \"out_dir\": \"/content/drive/MyDrive/models/role-aware-rag/distilbart\"\n",
        "    }\n",
        "\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRhJbwECyufT",
        "outputId": "c7971937-f040-4fc1-8d96-5daa548afba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yBEoCY4yzDaC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c60e6611607c4ddc9c072448eb829098",
            "aedb61b4120f40a9a532480c8f87d2fd",
            "19b404e06b57477ea161e8afee216cbd",
            "f0c6996a8431473f941207db2c8ae4df",
            "ede79aa96d264974a34850cc89d3062d",
            "351f17f057994994a3333f7044d4cad5",
            "51c76467912949189bd9bd69e3fcf940",
            "3dd8edff386e4941b9486909d995f657",
            "0347b2aecab04d5ca910163859282449",
            "00c7462083684dafb0a9befb5e05856b",
            "99113fdb4da74d64b892720b8eab82f6"
          ]
        },
        "outputId": "ec2ea931-95fd-4202-e261-bcea888a66b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c60e6611607c4ddc9c072448eb829098"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#load dataset\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/role_aware_squad.json\",\n",
        "    split=\"train\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kYhXPQLEpx8q"
      },
      "outputs": [],
      "source": [
        "#balance dataset into answerable and unanswerable questions\n",
        "def balance_role_dataset(dataset, per_role_count=500):\n",
        "\n",
        "    role_data = defaultdict(lambda: {\"answerable\": [], \"unanswerable\": []})\n",
        "\n",
        "    for i, example in enumerate(dataset):\n",
        "        if i < 1000:\n",
        "          continue\n",
        "        for role in [\"EMPLOYER\", \"EMPLOYEE\", \"CUSTOMER\"]:\n",
        "            answerable = example[\"role_answerable\"][role]\n",
        "            entry = {\n",
        "                \"question\": example[\"question\"],\n",
        "                \"original_context\": example[\"original_context\"],\n",
        "                \"original_answer\": example[\"original_answer\"],\n",
        "                \"role_context\": example[\"role_contexts\"][role],\n",
        "                \"is_answerable\": answerable,\n",
        "                \"role\": role\n",
        "            }\n",
        "            category = \"answerable\" if answerable else \"unanswerable\"\n",
        "            role_data[role][category].append(entry)\n",
        "\n",
        "    # Sample balanced set\n",
        "    balanced_examples = []\n",
        "    for role in role_data:\n",
        "        ans = role_data[role][\"answerable\"]\n",
        "        unans = role_data[role][\"unanswerable\"]\n",
        "\n",
        "        sampled = ans[:per_role_count] + unans[:per_role_count]\n",
        "        balanced_examples.extend(sampled)\n",
        "\n",
        "    return balanced_examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_dataset = balance_role_dataset(dataset)"
      ],
      "metadata": {
        "id": "VOphmf0M4_yu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3xfunuso3se4"
      },
      "outputs": [],
      "source": [
        "def mask_context(context, role, tokenizer, model):\n",
        "    prompt = f\"\"\"Please mask all PERSON, ORG, LOCATION, and DATE entities from the following text, considering the role {role}:\\n{context}\"\"\"\n",
        "\n",
        "    gen_cfg = model.generation_config\n",
        "\n",
        "    # Ensure early_stopping is properly set\n",
        "    if gen_cfg.early_stopping is None:\n",
        "        gen_cfg = GenerationConfig.from_model_config(model.config)\n",
        "        gen_cfg.early_stopping = True          # or False, or \"never\"\n",
        "        gen_cfg.num_beams = getattr(gen_cfg, \"num_beams\", 4)\n",
        "        gen_cfg.max_new_tokens = getattr(gen_cfg, \"max_new_tokens\", 512)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "    output = model.generate(**inputs, generation_config=gen_cfg)\n",
        "\n",
        "    # Return only a single decoded string\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c0zNnX6F5scp"
      },
      "outputs": [],
      "source": [
        "def final_prompt(query, context):\n",
        "    return f\"\"\"\n",
        "    You are not allowed to use any outside knowledge, training data, or prior information. You must only answer based on the text provided below. If a detail (such as a name) is not explicitly written in the text, respond by saying \"The information is not provided in the source.\"\n",
        "\n",
        "    [BEGIN SOURCE TEXT]\n",
        "    {context}\n",
        "    [END SOURCE TEXT]\n",
        "\n",
        "    Please answer the question\n",
        "    Question: {query}\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-HA84xatQGQ_"
      },
      "outputs": [],
      "source": [
        "def is_actual_answer(response):\n",
        "\n",
        "    response_clean = response.strip().lower()\n",
        "\n",
        "    # List of phrases that indicate no answer was found\n",
        "    denial_phrases = [\n",
        "        \"is not provided\",\n",
        "        \"not provided\",\n",
        "        \"is not available\",\n",
        "        \"not provided in the source\",\n",
        "        \"not mentioned in the source\",\n",
        "        \"the source does not provide\",\n",
        "        \"cannot be found in the source\",\n",
        "    ]\n",
        "\n",
        "    # Check if response matches any denial phrase\n",
        "    for phrase in denial_phrases:\n",
        "        if phrase in response_clean:\n",
        "            return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cFlqlCGsMjiS"
      },
      "outputs": [],
      "source": [
        "#save data to file\n",
        "output_path = '/content/drive/MyDrive/llm_rag_eval_heuristic_results_llama.csv'\n",
        "\n",
        "fieldnames = [\n",
        "    \"index\", \"role\", \"question\", \"masked_context\",\n",
        "    \"llm_answer\", \"llm_says_answerable\",\n",
        "    \"original_answer\", \"is_heuristically_answerable\", \"model\"\n",
        "]\n",
        "\n",
        "#check if file exists\n",
        "file_exists = os.path.isfile(output_path)\n",
        "\n",
        "# open file\n",
        "with open(output_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "\n",
        "    if not file_exists:\n",
        "        writer.writeheader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8isKXicV1ZnK"
      },
      "outputs": [],
      "source": [
        "#process through the whole rag\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "results = []\n",
        "existing_indices = set()\n",
        "\n",
        "if os.path.isfile(output_path):\n",
        "    with open(output_path, mode='r', encoding='utf-8') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            existing_indices.add(int(row['index']))\n",
        "\n",
        "index_counter = 0\n",
        "\n",
        "for model_config in MASKED_MODEL_CONFIG:\n",
        "  tokenizer = model_config['tokenizer_cls'].from_pretrained(model_config['out_dir'])\n",
        "  model = model_config['model_cls'].from_pretrained(model_config['out_dir']).to(device)\n",
        "  for i in range(2500):\n",
        "    index_counter += 1\n",
        "    if index_counter in existing_indices:\n",
        "      continue\n",
        "    role = balanced_dataset[i]['role']\n",
        "    question = balanced_dataset[i]['question']\n",
        "    context = balanced_dataset[i]['original_context']\n",
        "    masked_contexts = mask_context(context, role, tokenizer, model)\n",
        "\n",
        "    # Prompt + LLM\n",
        "    prompt = final_prompt(question, masked_contexts)\n",
        "\n",
        "    client = OpenAI(\n",
        "      base_url=\"https://ki32sz6gk1njugbq.us-east-1.aws.endpoints.huggingface.cloud/v1/\",\n",
        "      api_key=HF_TOKEN\n",
        "    )\n",
        "\n",
        "    r = client.chat.completions.create(\n",
        "        model = \"tgi\",\n",
        "        messages = [\n",
        "          {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "          }\n",
        "        ],\n",
        "        max_tokens=512\n",
        "      )\n",
        "    response = r.choices[0].message.content\n",
        "    bool_answer = is_actual_answer(response)\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    with open(output_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "      writer = csv.DictWriter(file, fieldnames=[\n",
        "          \"index\", \"role\", \"question\", \"masked_context\",\n",
        "          \"llm_answer\", \"llm_says_answerable\",\n",
        "          \"original_answer\", \"is_heuristically_answerable\", \"model\"\n",
        "      ])\n",
        "      writer.writerow({\n",
        "          \"index\": index_counter,\n",
        "          \"role\": role,\n",
        "          \"question\": question,\n",
        "          \"masked_context\": joined_masked_context,\n",
        "          \"llm_answer\": response,\n",
        "          \"llm_says_answerable\": bool_answer,\n",
        "          \"original_answer\": balanced_dataset[i]['original_answer'],\n",
        "          \"is_heuristically_answerable\": balanced_dataset[i]['is_answerable'],\n",
        "          \"model\": model_config['name']\n",
        "      })\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c60e6611607c4ddc9c072448eb829098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aedb61b4120f40a9a532480c8f87d2fd",
              "IPY_MODEL_19b404e06b57477ea161e8afee216cbd",
              "IPY_MODEL_f0c6996a8431473f941207db2c8ae4df"
            ],
            "layout": "IPY_MODEL_ede79aa96d264974a34850cc89d3062d"
          }
        },
        "aedb61b4120f40a9a532480c8f87d2fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351f17f057994994a3333f7044d4cad5",
            "placeholder": "​",
            "style": "IPY_MODEL_51c76467912949189bd9bd69e3fcf940",
            "value": "Generating train split: "
          }
        },
        "19b404e06b57477ea161e8afee216cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd8edff386e4941b9486909d995f657",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0347b2aecab04d5ca910163859282449",
            "value": 1
          }
        },
        "f0c6996a8431473f941207db2c8ae4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c7462083684dafb0a9befb5e05856b",
            "placeholder": "​",
            "style": "IPY_MODEL_99113fdb4da74d64b892720b8eab82f6",
            "value": " 10000/0 [00:01&lt;00:00, 11428.28 examples/s]"
          }
        },
        "ede79aa96d264974a34850cc89d3062d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351f17f057994994a3333f7044d4cad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c76467912949189bd9bd69e3fcf940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd8edff386e4941b9486909d995f657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0347b2aecab04d5ca910163859282449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00c7462083684dafb0a9befb5e05856b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99113fdb4da74d64b892720b8eab82f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}